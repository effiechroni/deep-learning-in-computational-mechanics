{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffbf192-4ba9-4aa9-a90a-4974e829bc39",
   "metadata": {},
   "source": [
    "# Exercise 27 - Physics-Informed Neural Networks for Inverse Problems\n",
    "### Task\n",
    "Compare the effect of a linear, a fully connected neural network, and a convolutional neural network ansatz on the inversion quality of a physics-informed neural network for full waveform inversion. The ansatz is defined via `selectModel`. If necessary, adjust the number of epochs. \n",
    "\n",
    "### Learning goals\n",
    "- Familiarize yourself with the syntax of the physics-informed neural network for full domain full waveform inversion\n",
    "- Gain intuition about the three ansatz formulations for the material distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce013e-5489-4095-8050-bd23f7b9b729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:30.644938Z",
     "start_time": "2024-10-24T05:58:30.642360Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fc2062a7fa73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:30.792417Z",
     "start_time": "2024-10-24T05:58:30.786329Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15a3ef45f8dc4e",
   "metadata": {},
   "source": [
    "## Select material distribution ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef37d61767e38b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:31.064885Z",
     "start_time": "2024-10-24T05:58:31.062284Z"
    }
   },
   "outputs": [],
   "source": [
    "#selectModel = \"Linear\" \n",
    "selectModel = \"FNN\"\n",
    "#selectModel = \"CNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d647c",
   "metadata": {},
   "source": [
    "## Ansatz helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190661ee1d02bb39",
   "metadata": {},
   "source": [
    "**weight initialization and normalization for convolutional layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9ae75151f7f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:31.459138Z",
     "start_time": "2024-10-24T05:58:31.454976Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"Initialize weights of neural network with xavier initialization.\"\"\"\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=torch.nn.init.calculate_gain('leaky_relu', 0.2))\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "class PixelNorm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / torch.sqrt(torch.sum(x ** 2, axis=(2), keepdim=True) / x.shape[2] + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8f67e29ea8865",
   "metadata": {},
   "source": [
    "**linear ansatz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a7d4d7fd275b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:31.737752Z",
     "start_time": "2024-10-24T05:58:31.734868Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearAnsatz(torch.nn.Module):\n",
    "    def __init__(self, Nx, device, init=1.):\n",
    "        super().__init__()\n",
    "        self.coefficients = torch.nn.Parameter(torch.ones((1, 1, Nx + 3), device=device) * init)\n",
    "\n",
    "    def forward(self, dummy):\n",
    "        return self.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ddb6bcd65d65a7",
   "metadata": {},
   "source": [
    "**fully connected neural network ansatz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2c510e9877582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:32.014482Z",
     "start_time": "2024-10-24T05:58:32.009719Z"
    }
   },
   "outputs": [],
   "source": [
    "class FNN(torch.nn.Module):\n",
    "    def __init__(self, input_dimension, hidden_dimension, output_dimension):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "        modules.append(torch.nn.Linear(input_dimension, hidden_dimension[0]))\n",
    "        modules.append(torch.nn.PReLU(init=0.2))\n",
    "        for i in range(len(hidden_dimension) - 1):\n",
    "            modules.append(torch.nn.Linear(hidden_dimension[i], hidden_dimension[i + 1]))\n",
    "            modules.append(torch.nn.PReLU(init=0.2))\n",
    "\n",
    "        modules.append(torch.nn.Linear(hidden_dimension[-1], output_dimension))\n",
    "\n",
    "        # Scale output between 0 and 1 with Sigmoid\n",
    "        modules.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "        self.model.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze().unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c73bd5a6b5cdb",
   "metadata": {},
   "source": [
    "**convolutional neural network ansatz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f5d189a0bf29b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:32.216909Z",
     "start_time": "2024-10-24T05:58:32.212051Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "        modules.append(torch.nn.Conv1d(128, 64, kernel_size=3, padding=1, stride=1))\n",
    "        modules.append(torch.nn.PReLU(init=0.2))\n",
    "        modules.append(PixelNorm())\n",
    "        modules.append(torch.nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(64, 32, kernel_size=3, padding=1, stride=1))\n",
    "        modules.append(torch.nn.PReLU(init=0.2))\n",
    "        modules.append(PixelNorm())\n",
    "        modules.append(torch.nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(32, 16, kernel_size=3, padding=1, stride=1))\n",
    "        modules.append(torch.nn.PReLU(init=0.2))\n",
    "        modules.append(PixelNorm())\n",
    "        modules.append(torch.nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(16, 1, kernel_size=3, padding=1, stride=1))\n",
    "\n",
    "        # Scale output between 0 and 1 with Sigmoid\n",
    "        modules.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "        self.model.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88eccdccf3806e4",
   "metadata": {},
   "source": [
    "## Physics-informed residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124dadecfd00e04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:32.438182Z",
     "start_time": "2024-10-24T05:58:32.433962Z"
    }
   },
   "outputs": [],
   "source": [
    "def getResidual(cpred, um, fm, i, dx, dt):\n",
    "    upred = um[i]  # should also be a NN in case of partial domain knowledge\n",
    "    f = fm[i]\n",
    "\n",
    "    utt = (upred[:, 2:] - 2 * upred[:, 1:-1] + upred[:, :-2])\n",
    "\n",
    "    c2uxx = (dt / dx) ** 2 * ((0.5 / cpred[1:-1] ** 2 + 0.5 / cpred[2:] ** 2) ** (-1) * (upred[2:] - upred[1:-1]) - \\\n",
    "                              (0.5 / cpred[:-2] ** 2 + 0.5 / cpred[1:-1] ** 2) ** (-1) * (upred[1:-1] - upred[:-2]))\n",
    "\n",
    "    return (utt[1:-1] - c2uxx[:, 1:-1] - f[1:-1, :-1] * dt ** 2) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af70f61d816afe4",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5adda66f6d5965",
   "metadata": {},
   "source": [
    "**loading settings of measurement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26133e3bb0bb8749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:32.869825Z",
     "start_time": "2024-10-24T05:58:32.819150Z"
    }
   },
   "outputs": [],
   "source": [
    "settings = pd.read_csv(\"measurement1DFWI/settings.csv\")\n",
    "\n",
    "Lx = settings.Lx[0]\n",
    "Nx = settings.Nx[0]\n",
    "dx = Lx / Nx\n",
    "dt = settings.dt[0]\n",
    "N = settings.N[0]\n",
    "c0 = settings.c0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceed73c8808351c",
   "metadata": {},
   "source": [
    "**grid creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3dfd64a194e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:33.057307Z",
     "start_time": "2024-10-24T05:58:33.042681Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(0 - dx, Lx + dx, Nx + 3, device=device)  # with ghost cells\n",
    "t = torch.linspace(0, (N - 1) * dt, N, device=device)\n",
    "x_, t_ = torch.meshgrid(x, t, indexing='ij')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202544fd292670b7",
   "metadata": {},
   "source": [
    "**loading measurements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860053ed27ea137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:33.254089Z",
     "start_time": "2024-10-24T05:58:33.238444Z"
    }
   },
   "outputs": [],
   "source": [
    "numberOfSources = 2\n",
    "fm = torch.zeros((numberOfSources, Nx + 1, N))\n",
    "um = torch.zeros((numberOfSources, Nx + 1, N + 1))\n",
    "for i in range(numberOfSources):\n",
    "    fm[i] = torch.tensor(pd.read_hdf(\"measurement1DFWI/source\" + str(i) + \".h5\").values, device=device)\n",
    "    um[i] = torch.tensor(pd.read_hdf(\"measurement1DFWI/signal\" + str(i) + \".h5\").values, device=device)\n",
    "cm = torch.tensor(pd.read_hdf(\"measurement1DFWI/material.h5\").values, device=device)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f971cc158446506f",
   "metadata": {},
   "source": [
    "## Hyperparameter selection & model/ansatz initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8011e71124f010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:33.568526Z",
     "start_time": "2024-10-24T05:58:33.545964Z"
    }
   },
   "outputs": [],
   "source": [
    "if selectModel == \"Linear\":\n",
    "    model = LinearAnsatz(Nx, device)\n",
    "    modelInput = x.unsqueeze(1)  # dummy\n",
    "    print(x.shape)\n",
    "\n",
    "    # hyperparameters\n",
    "    lr = 1e-2\n",
    "    alpha = -0.5\n",
    "    beta = 0.2\n",
    "    epochs = 1000\n",
    "    costScaling = 1e8\n",
    "    clip = 1e-4\n",
    "    weightLrFactor = 10\n",
    "\n",
    "elif selectModel == \"FNN\":\n",
    "    model = FNN(1, [100, 100, 100], 1)\n",
    "    modelInput = x.unsqueeze(1)\n",
    "    modelInput = (modelInput - torch.min(modelInput)) / (\n",
    "            torch.max(modelInput) - torch.min(modelInput)) * 2 - 1  # normalize and center input data\n",
    "\n",
    "    lr = 2e-3\n",
    "    alpha = -0.2\n",
    "    beta = 0.2\n",
    "    epochs = 1000  # 10000\n",
    "    clip = 1e-3\n",
    "    weightLrFactor = 10\n",
    "\n",
    "elif selectModel == \"CNN\":\n",
    "    model = CNN()\n",
    "    modelInput = torch.randn((1, 128, 15), device=device)\n",
    "    modelInput = (modelInput - torch.min(modelInput)) / (\n",
    "            torch.max(modelInput) - torch.min(modelInput)) * 2 - 1  # normalize and center input data\n",
    "\n",
    "    # hyperparameters\n",
    "    lr = 1e-2\n",
    "    alpha = -0.2\n",
    "    beta = 0.5\n",
    "    epochs = 1000\n",
    "    costScaling = 1e8\n",
    "    clip = 1e-3\n",
    "    weightLrFactor = 10\n",
    "\n",
    "print(\"number of parameters: {:d}\".format(\n",
    "    np.sum(np.array([len(list(model.parameters())[i].flatten()) for i in range(len(list(model.parameters())))]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570161572f1c58a",
   "metadata": {},
   "source": [
    "## Optimizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53815362f61e08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T16:01:09.386854Z",
     "start_time": "2024-10-23T16:01:09.372268Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "weights = torch.ones((Nx - 1, N - 1), requires_grad=True, dtype=torch.float, device=device)\n",
    "optimizer.add_param_group({'params': weights})\n",
    "optimizer.param_groups[-1]['lr'] = lr * weightLrFactor\n",
    "\n",
    "lr_lambda = lambda epoch: (beta * epoch + 1) ** alpha\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ea1a48c7d75d1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58918cc1170c55cb",
   "metadata": {},
   "source": [
    "**training setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d019657bb9f8d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:56:02.678422Z",
     "start_time": "2024-10-24T05:56:02.663421Z"
    }
   },
   "outputs": [],
   "source": [
    "costHistory = np.zeros(epochs)\n",
    "start = time.perf_counter()\n",
    "start0 = start\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd32056711aa0",
   "metadata": {},
   "source": [
    "**training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af72bfbdc24cc88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T16:01:09.865175Z",
     "start_time": "2024-10-23T16:01:09.842823Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    cpred = model(modelInput)[0, 0, 1:-1].unsqueeze(1) * c0\n",
    "\n",
    "    residual = torch.zeros((Nx - 1, N - 1))\n",
    "    for i in range(2):\n",
    "        residual += getResidual(cpred, um, fm, i, dx, dt)\n",
    "\n",
    "    cost = torch.sum(weights * residual)\n",
    "    costUnweighted = torch.sum(residual.detach())\n",
    "    cost.backward()\n",
    "    weights.grad *= -1\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.param_groups[-1]['lr'] = optimizer.param_groups[0][\n",
    "                                           'lr'] * weightLrFactor  # countering of how scheduler treats all learning rates in the same manner\n",
    "\n",
    "    costHistory[epoch] = costUnweighted\n",
    "\n",
    "    if (epoch % 100 == 0):\n",
    "        elapsed_time = time.perf_counter() - start\n",
    "        string = \"Epoch: {}/{}\\t\\tCost function: {:.3E}\\t\\tElapsed time: {:2f}\"\n",
    "        print(string.format(epoch, epochs - 1, costHistory[epoch], elapsed_time))\n",
    "        start = time.perf_counter()\n",
    "\n",
    "print(\"Total elapsed training time: {:2f}\".format(time.perf_counter() - start0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cd336970435e18",
   "metadata": {},
   "source": [
    "**prediction of material distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488e2206c4b7f5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T16:01:10.040741Z",
     "start_time": "2024-10-23T16:01:10.018958Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "cpred = model(modelInput)[0, 0, 1:-1].detach() * c0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ddade37bc81a57",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c179c7f0b317ac",
   "metadata": {},
   "source": [
    "**predicted material distribution & true material distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ea638c0d60395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T16:01:10.414634Z",
     "start_time": "2024-10-23T16:01:10.285083Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x[1:-1], cm[1:-1], 'gray')\n",
    "ax.plot(x[1:-1], cpred, 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2119b796bb5fd",
   "metadata": {},
   "source": [
    "**learning history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f998f0ec2e489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T16:00:48.736219Z",
     "start_time": "2024-10-23T16:00:48.724656Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(costHistory, 'k')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178f93aaf703238",
   "metadata": {},
   "source": [
    "**spatio-temporal residual distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb06e63e954a07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T16:00:58.167181Z",
     "start_time": "2024-10-23T16:00:58.131191Z"
    }
   },
   "outputs": [],
   "source": [
    "frequency = settings.frequency[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "cp = ax.pcolormesh(x_[2:-2, :-1] / Lx, t_[2:-2, :-1] * frequency, residual.detach() + 1e-80, cmap=plt.cm.jet,\n",
    "                   norm=matplotlib.colors.LogNorm(), shading='auto')\n",
    "ax.set_xlabel('$x / L_x$ [-]')\n",
    "ax.set_ylabel('$t f$ [-]')\n",
    "fig.colorbar(cp)\n",
    "ax.set_title(\"residual in $u$\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92ba674a9824c70",
   "metadata": {},
   "source": [
    "**spatio-temporal weighting distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f39914b7fbb42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "cp = ax.pcolormesh(x_[2:-2, :-1] / Lx, t_[2:-2, :-1] * frequency, weights.detach(), cmap=plt.cm.jet, shading='auto')\n",
    "ax.set_xlabel('$x / L_x$ [-]')\n",
    "ax.set_ylabel('$t f$ [-]')\n",
    "fig.colorbar(cp)\n",
    "ax.set_title(\"final weights $\\\\kappa$\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
