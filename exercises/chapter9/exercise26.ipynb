{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffbf192-4ba9-4aa9-a90a-4974e829bc39",
   "metadata": {},
   "source": [
    "# Exercise 26 - Neural Network Ansatz on Optimization Benchmarks\n",
    "### Task\n",
    "Compare a linear and neural network ansatz for different optimization benchmark functions (rosenbrock, rastrigrin, ackley, levy) using six different optimizers (steepest descent, steepest descent with momentum, adagrad, rmsprop, adam, lbfgs)\n",
    "\n",
    "### Learning goals\n",
    "- Familiarize yourself with the syntax of the neural network ansatz for optimization problems\n",
    "- Understand how and when a neural network ansatz becomes beneficial for an optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce013e-5489-4095-8050-bd23f7b9b729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:59:35.082802Z",
     "start_time": "2024-10-23T13:59:35.080408Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import torch\n",
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d647c",
   "metadata": {},
   "source": [
    "## Select benchmark function, optimizer, and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190661ee1d02bb39",
   "metadata": {},
   "source": [
    "**benchmark function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56496a44ca0c963",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:02:17.578764Z",
     "start_time": "2024-10-23T14:02:17.575566Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = \"rosenbrock\"\n",
    "#benchmark = \"rastrigrin\" \n",
    "#benchmark = \"ackley\" \n",
    "#benchmark = \"levy\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa7a88965c3456",
   "metadata": {},
   "source": [
    "**optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5161e39ca943c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:59:45.981628Z",
     "start_time": "2024-10-23T13:59:45.978347Z"
    }
   },
   "outputs": [],
   "source": [
    "#selectOptimizer = 'steepestDescent'\n",
    "#selectOptimizer = 'steepestDescentWithMomentum' \n",
    "#selectOptimizer = 'adagrad' \n",
    "#selectOptimizer = 'rmsprop' \n",
    "selectOptimizer = 'adam'\n",
    "#selectOptimizer = 'lbfgs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9636d86300d2977",
   "metadata": {},
   "source": [
    "**hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25d2507e464c00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:53.137793Z",
     "start_time": "2024-10-23T13:56:53.134961Z"
    }
   },
   "outputs": [],
   "source": [
    "initialGuess = torch.tensor([[3, 3]])\n",
    "lrTuningEpochs = 20\n",
    "gridPoints = 50\n",
    "epochs = 300\n",
    "neurons = 50\n",
    "layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da07d40e09e2f66",
   "metadata": {},
   "source": [
    "## Neural network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6229ec1aad32c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:53.218931Z",
     "start_time": "2024-10-23T13:56:53.212819Z"
    }
   },
   "outputs": [],
   "source": [
    "class FNN(torch.nn.Module):\n",
    "    def __init__(self, neurons, layers, y0, x0, kaiming=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(10, neurons)\n",
    "        self.linear2 = torch.nn.ModuleList()\n",
    "        for i in range(self.layers):\n",
    "            self.linear2.append(torch.nn.Linear(neurons, neurons))\n",
    "        self.linear3 = torch.nn.Linear(neurons, 2)\n",
    "        self.activation = torch.nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        if kaiming == True:\n",
    "            torch.nn.init.kaiming_uniform_(self.linear1.weight, nonlinearity='leaky_relu')\n",
    "            torch.nn.init.constant_(self.linear1.bias, 0)\n",
    "            for i in range(self.layers):\n",
    "                torch.nn.init.kaiming_uniform_(self.linear2[i].weight, nonlinearity='leaky_relu')\n",
    "                torch.nn.init.constant_(self.linear2[i].bias, 0)\n",
    "            torch.nn.init.kaiming_uniform_(self.linear3.weight, nonlinearity='leaky_relu')\n",
    "            torch.nn.init.constant_(self.linear3.bias, 0)\n",
    "\n",
    "        # adjust initial guess   \n",
    "        self.adjust = 0\n",
    "        with torch.no_grad():\n",
    "            y0Pred = self.forward(x0)\n",
    "            self.adjust = y0Pred - y0\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.activation(self.linear1(x))\n",
    "        for i in range(self.layers):\n",
    "            y = self.activation(self.linear2[i](y))\n",
    "        y = self.linear3(y)\n",
    "        return y - self.adjust\n",
    "\n",
    "\n",
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, y0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = torch.nn.Linear(1, 2, bias=False)\n",
    "        self.linear.weight.data *= 0\n",
    "        self.y0 = y0.detach()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(torch.tensor([[1.]])) + self.y0\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fad663c1b852d9",
   "metadata": {},
   "source": [
    "## Benchmark selection and derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9ae75151f7f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:53.266685Z",
     "start_time": "2024-10-23T13:56:53.261478Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark == \"rosenbrock\":\n",
    "    f = lambda y: 100 * (y[:, 1:2] - y[:, 0:1] ** 2) ** 2 + (1 - y[:, 0:1]) ** 2\n",
    "elif benchmark == \"rastrigrin\":\n",
    "    f = lambda y: 20 + y[:, 0:1] ** 2 - 10 * torch.cos(2 * np.pi * y[:, 0:1]) + y[:, 1:2] ** 2 - 10 * torch.cos(\n",
    "        2 * np.pi * y[:, 1:2])\n",
    "elif benchmark == \"ackley\":\n",
    "    f = lambda y: - 20 * torch.exp(-0.2 * torch.sqrt(0.5 * (y[:, 0:1] ** 2 + y[:, 1:2] ** 2))) \\\n",
    "                  - torch.exp(0.5 * (torch.cos(2 * np.pi * y[:, 0:1]) + torch.cos(2 * np.pi * y[:, 1:2]))) + np.exp(\n",
    "        1) + 20\n",
    "elif benchmark == \"levy\":\n",
    "    f = lambda y: torch.sin(3 * np.pi * (y[:, 0:1] + 1)) ** 2 + ((y[:, 0:1] + 1) - 1) ** 2 * (\n",
    "            1 + torch.sin(3 * np.pi * (y[:, 1:2] + 1)) ** 2) \\\n",
    "                  + ((y[:, 1:2] - 1) + 1) ** 2 * (1 + torch.sin(2 * np.pi * (y[:, 1:2] + 1)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c50b1779f549c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:53.355096Z",
     "start_time": "2024-10-23T13:56:53.351061Z"
    }
   },
   "outputs": [],
   "source": [
    "def dfdy(y):\n",
    "    y0 = y[:, 0:1].detach()\n",
    "    y1 = y[:, 1:2].detach()\n",
    "    y0.requires_grad = True\n",
    "    y1.requires_grad = True\n",
    "\n",
    "    z = f(torch.cat((y0, y1), 1))\n",
    "\n",
    "    dfdy0 = grad(z, y0, torch.ones_like(z), retain_graph=True)[0]\n",
    "    dfdy1 = grad(z, y1, torch.ones_like(z))[0]\n",
    "\n",
    "    return torch.cat((dfdy0, dfdy1), 1)\n",
    "\n",
    "\n",
    "def getInverseHessian(y):\n",
    "    return torch.linalg.inv(torch.autograd.functional.hessian(f, y)[0, :, 0, :]).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e47de3fc272ac",
   "metadata": {},
   "source": [
    "## Training algorithm and learning rate tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b905bcda72b789",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:53.412979Z",
     "start_time": "2024-10-23T13:56:53.407664Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainModel(model, xInput, lr, epochs, keepModel=False, selectOptimizer='adam'):\n",
    "    torch.save(model.state_dict(), \"tempModel\")\n",
    "    if selectOptimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif selectOptimizer == 'steepestDescent':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    elif selectOptimizer == 'lbfgs':\n",
    "        optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "    elif selectOptimizer == 'steepestDescentWithMomentum':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    elif selectOptimizer == 'rmsprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    elif selectOptimizer == 'adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "    yHistory = np.zeros((epochs, 2))\n",
    "    zHistory = np.zeros((epochs, 1))\n",
    "    for epoch in range(epochs):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            y = model(xInput)\n",
    "            cost = f(y)\n",
    "            cost.backward()\n",
    "            return cost\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y = model(xInput)\n",
    "            yHistory[epoch] = y.detach()[0]\n",
    "            zHistory[epoch] = f(y).detach()[0, 0]\n",
    "            optimizer.step(closure)\n",
    "\n",
    "    if keepModel == False:\n",
    "        model.load_state_dict(torch.load(\"tempModel\", weights_only=True))\n",
    "    return yHistory, zHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a48ae1a11b0b68c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:53.463761Z",
     "start_time": "2024-10-23T13:56:53.460047Z"
    }
   },
   "outputs": [],
   "source": [
    "def gridSearchForLr(model, xInput, epochs, gridPoints=10, selectOptimizer='adam'):\n",
    "    if selectOptimizer == 'adam':\n",
    "        lrs = np.logspace(-2, 0, gridPoints)\n",
    "    elif selectOptimizer == 'steepestDescent':\n",
    "        lrs = np.logspace(-6, -3, gridPoints)\n",
    "    elif selectOptimizer == 'lbfgs':\n",
    "        lrs = np.logspace(-2, 1, gridPoints)\n",
    "    elif selectOptimizer == 'rmsprop':\n",
    "        lrs = np.logspace(-4, 0, gridPoints)  # not tuned\n",
    "    elif selectOptimizer == 'adagrad':\n",
    "        lrs = np.logspace(-2, 1, gridPoints)\n",
    "    elif selectOptimizer == 'steepestDescentWithMomentum':\n",
    "        lrs = np.logspace(-6, -4, gridPoints)\n",
    "    costs = np.zeros_like(lrs)\n",
    "    for i, lr in enumerate(lrs):\n",
    "        costs[i] = trainModel(model, xInput, lr, epochs, selectOptimizer=selectOptimizer)[1][-1]\n",
    "    return lrs[np.nanargmin(costs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bb9931f46ffad8",
   "metadata": {},
   "source": [
    "## Model initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2598128ffa762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:53.527169Z",
     "start_time": "2024-10-23T13:56:53.524900Z"
    }
   },
   "outputs": [],
   "source": [
    "xInput = torch.rand((1, 10)) * 2 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4129fa078d42dc3",
   "metadata": {},
   "source": [
    "**linear ansatz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36a05285c0f518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:54.315312Z",
     "start_time": "2024-10-23T13:56:53.575276Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Linear(initialGuess)\n",
    "lr = gridSearchForLr(model, xInput, lrTuningEpochs, gridPoints, selectOptimizer=selectOptimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a97ef4fef26160",
   "metadata": {},
   "source": [
    "**neural network ansatz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78867bb4067d5cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:56.981359Z",
     "start_time": "2024-10-23T13:56:54.345215Z"
    }
   },
   "outputs": [],
   "source": [
    "modelNN = FNN(neurons, layers, initialGuess, xInput)\n",
    "lrNN = gridSearchForLr(modelNN, xInput, lrTuningEpochs, gridPoints, selectOptimizer=selectOptimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c9f4dd9978f71",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6c7d66296beaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:57.690497Z",
     "start_time": "2024-10-23T13:56:57.012753Z"
    }
   },
   "outputs": [],
   "source": [
    "yHistoryLinear, zHistoryLinear = trainModel(model, xInput, lr, epochs, selectOptimizer=selectOptimizer)\n",
    "yHistoryNN, zHistoryNN = trainModel(modelNN, xInput, lrNN, epochs, selectOptimizer=selectOptimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1164f44d68b31",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0af5c920fa222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:58.965009Z",
     "start_time": "2024-10-23T13:56:57.722644Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark == 'rosenbrock':\n",
    "    plotRangex = [-2, 4]\n",
    "    plotRangey = [-1, 5]\n",
    "else:\n",
    "    plotRangex = [-3.5, 3.5]\n",
    "    plotRangey = [-3.5, 3.5]\n",
    "\n",
    "x_ = torch.linspace(plotRangex[0], plotRangex[1], 300)\n",
    "y_ = torch.linspace(plotRangey[0], plotRangey[1], 300)\n",
    "x_, y_ = torch.meshgrid(x_, y_, indexing='ij')\n",
    "y = torch.reshape(torch.cat((x_.unsqueeze(2), y_.unsqueeze(2)), 2), (300 * 300, 2))\n",
    "z = torch.reshape(f(y), (300, 300))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "if benchmark == 'rosenbrock':\n",
    "    norm = colors.LogNorm()\n",
    "else:\n",
    "    norm = colors.Normalize()  # default\n",
    "cp = ax.pcolormesh(x_, y_, z, norm=norm, cmap=plt.cm.jet, shading='auto')\n",
    "ax.contour(x_, y_, z, norm=norm, cmap=plt.cm.hot)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "if benchmark == 'rosenbrock':\n",
    "    ax.plot(1, 1, 'ws', markersize=16)  # optimum\n",
    "else:\n",
    "    ax.plot(0, 0, 'ws', markersize=16)  # optimum\n",
    "\n",
    "ax.plot(yHistoryNN[:, 0], yHistoryNN[:, 1], '.', color='b', markersize=12)  # NN path\n",
    "ax.plot(yHistoryNN[:, 0], yHistoryNN[:, 1], color='b', linewidth=4, label='NN')  # NN path\n",
    "ax.plot(yHistoryNN[-1, 0], yHistoryNN[-1, 1], 'o', color='b', markersize=12)\n",
    "\n",
    "ax.plot(yHistoryLinear[:, 0], yHistoryLinear[:, 1], 'k.', markersize=12)  # linear path\n",
    "ax.plot(yHistoryLinear[:, 0], yHistoryLinear[:, 1], 'k', linewidth=4, label='linear')  # linear path\n",
    "ax.plot(yHistoryLinear[-1, 0], yHistoryLinear[-1, 1], 'ko', markersize=12)\n",
    "\n",
    "ax.set_xlim(plotRangex[0], plotRangex[1])\n",
    "ax.set_ylim(plotRangey[0], plotRangey[1])\n",
    "\n",
    "ax.legend()\n",
    "fig.colorbar(cp)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e9bb29b83fd90",
   "metadata": {},
   "source": [
    "## Who was better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04491813ab21a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T13:56:59.028528Z",
     "start_time": "2024-10-23T13:56:59.022922Z"
    }
   },
   "outputs": [],
   "source": [
    "if f(torch.from_numpy(yHistoryNN[-2:-1, :]))[0, 0] < f(torch.from_numpy(yHistoryLinear[-2:-1, :]))[0, 0]:\n",
    "    print(\"NN outperformed Linear\")\n",
    "else:\n",
    "    print(\"Linear outperformed NN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
