{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ba11a8-9964-4b7e-b262-8b631b887188",
   "metadata": {},
   "source": [
    "# Exercise 13 - Physics-Informed Neural Network for a Static Bar\n",
    "### Task\n",
    "Implement a physics-informed neural network for a one-dimensional static bar\n",
    "1. define the distributed load `distLoad` according to the exercise description\n",
    "2. implement the prediction of the displacements (without strong enforcement) as `getDisplacements`\n",
    "3. implement the physics-informed and boundary loss computation as `getLossTerms`\n",
    "4. compute the cost function with `getCostFunction`\n",
    "5. Train the physics-informed neural network by executing the training loop\n",
    "6. Improve the convergence by adjusting the hyperparameters\n",
    "7. Reproduce the example from Section 4.2.1. by replacing the problem parameters\n",
    "\n",
    "### Learning goals\n",
    "- Understand how physics-informed neural networks work and how they are implemented\n",
    "- Gain an intuition about the performance of physics-informed neural networks and how the hyperparameters affect the convergence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc65ef-fdb0-409a-8b58-6ee22a3a38db",
   "metadata": {},
   "source": [
    "**import libraries & set seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfeb949-ac58-4b07-9687-c41064b91f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.306381476Z",
     "start_time": "2024-01-30T10:59:17.261313364Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aad52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287a8dc-3ef0-490c-a549-a4c06474f8b9",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837a3c0-c7e6-4750-94d6-07b83721493f",
   "metadata": {},
   "source": [
    "**gradient computation with automatic differentiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ff7cc-b51d-4a65-b314-06d55506104a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.309136225Z",
     "start_time": "2024-01-30T10:59:17.306473002Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDerivative(y, x, n):\n",
    "    \"\"\"Compute the nth order derivative of y = f(x) with respect to x.\"\"\"\n",
    "\n",
    "    if n == 0:\n",
    "        return y\n",
    "    else:\n",
    "        dy_dx = grad(\n",
    "            y, x, torch.ones(x.size()[0], 1), create_graph=True, retain_graph=True\n",
    "        )[0]\n",
    "        return getDerivative(dy_dx, x, n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351b4bd-8953-4816-87ac-fd5abb029b75",
   "metadata": {},
   "source": [
    "**neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa82fc-8100-4a35-9709-9f3ff1272515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.319156180Z",
     "start_time": "2024-01-30T10:59:17.311023315Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputDimension,\n",
    "        hiddenDimensions,\n",
    "        outputDimension,\n",
    "        activationFunction=torch.nn.Tanh(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        modules.append(torch.nn.Linear(inputDimension, hiddenDimensions[0]))\n",
    "        modules.append(activationFunction)\n",
    "        for i in range(len(hiddenDimensions) - 1):\n",
    "            modules.append(\n",
    "                torch.nn.Linear(hiddenDimensions[i], hiddenDimensions[i + 1])\n",
    "            )\n",
    "            modules.append(activationFunction)\n",
    "        modules.append(torch.nn.Linear(hiddenDimensions[-1], outputDimension))\n",
    "\n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997a44b-2089-42b8-b3cc-dcb75599c2d7",
   "metadata": {},
   "source": [
    "**initialization of neural network weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccef84d-eadf-4dc1-8298-b1062faa5f97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.326413268Z",
     "start_time": "2024-01-30T10:59:17.316648600Z"
    }
   },
   "outputs": [],
   "source": [
    "def initWeights(m):\n",
    "    \"\"\"Initialize weights of neural network with xavier initialization.\"\"\"\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(\n",
    "            m.weight, gain=torch.nn.init.calculate_gain(\"tanh\")\n",
    "        )  # adapt if using a different initialization\n",
    "        m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac280a6c-0742-4bf8-b6f2-0995b3680079",
   "metadata": {},
   "source": [
    "## PINN helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551c1ad-ef82-4af5-bc7c-658fb6d16913",
   "metadata": {},
   "source": [
    "**displacement computation**\n",
    "$$\\hat{u}=F_{NN}(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eda658-51ba-47bc-a7ff-ed2bb47c4c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.328770727Z",
     "start_time": "2024-01-30T10:59:17.322602052Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDisplacements(model, x):\n",
    "    return model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9999f25-b7e7-42fa-a1bd-4824a0a32fa3",
   "metadata": {},
   "source": [
    "**loss term computation**\n",
    "\n",
    "The differential equation loss\n",
    "$$\\mathcal{L}_R=\\sum_{i=1}^N\\bigl(\\frac{d}{dx}EA\\bigl(\\frac{d\\hat{u}}{dx}\\bigr)+p\\bigr)^2$$\n",
    "The boundary condition loss \n",
    "$$\\mathcal{L}_B=\\sum_{i=1}^{N_B}\\bigl( \\frac{d^{n_i} \\hat{u}}{dx^{n_i}} - F \\bigr)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e36d4-ee7e-4450-8c50-a4ba4fd101e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.359301668Z",
     "start_time": "2024-01-30T10:59:17.328568995Z"
    }
   },
   "outputs": [],
   "source": [
    "def getLossTerms(x, xB, u, uB, EA, distLoad, uBLabel):\n",
    "    differentialEquationLoss = (\n",
    "        getDerivative(EA * getDerivative(u, x, 1), x, 1) + distLoad\n",
    "    )\n",
    "    differentialEquationLoss = torch.sum(differentialEquationLoss**2).squeeze()\n",
    "\n",
    "    # initialization\n",
    "    boundaryConditionLoss = 0\n",
    "\n",
    "    for i in range(len(uBLabel)):\n",
    "        boundaryConditionLoss += (\n",
    "            getDerivative(uB, xB, uBLabel[i][1])[i] - uBLabel[i][0]\n",
    "        ).squeeze() ** 2\n",
    "\n",
    "    return differentialEquationLoss, boundaryConditionLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a48beb-255a-4042-b29b-bdf06a4cdd3a",
   "metadata": {},
   "source": [
    "**cost function computation**\n",
    "$$C=\\mathcal{L}_R+\\mathcal{L}_B$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbab3de-4767-45c9-a4d3-6bfb638d243a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.362342811Z",
     "start_time": "2024-01-30T10:59:17.328735277Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCostFunction(lossTerms):\n",
    "    return lossTerms[0] + lossTerms[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e7265-83d4-4be6-b5d2-018649c32b21",
   "metadata": {},
   "source": [
    "## Problem setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957569f-3de2-43dd-9b11-3221bf3d04b9",
   "metadata": {},
   "source": [
    "**physical parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7459465-221f-43d6-8c9f-0d7ff6938496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.371836001Z",
     "start_time": "2024-01-30T10:59:17.359342909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Analytial solution\n",
    "uAnalytic = lambda x: (1.0 - np.cos(3.0 * np.pi * x))\n",
    "\n",
    "# Problem data\n",
    "E = lambda x: 1.0  # Young's modulus\n",
    "A = lambda x: x**2 + 1.0  # cross-sectional area\n",
    "L = 3.0 / 2.0  # bar length\n",
    "uB = [\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "]  # boundary conditions: [value, degree of differentiation, coordinate]\n",
    "distLoad = lambda x: -6 * x * np.pi * torch.sin(3 * np.pi * x) - 9 * (\n",
    "    x**2 + 1\n",
    ") * np.pi**2 * torch.cos(\n",
    "    3 * np.pi * x\n",
    ")  # distributed load p(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f533b6-272e-460a-8355-0850025d400f",
   "metadata": {},
   "source": [
    "**hyperparameters**\n",
    "\n",
    "currently Adam is selected as optimizer. By commenting the Adam block and uncommenting the LBFGS block, you can enable LBFGS as optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15917078-13cb-4725-9164-cf409ada9530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.375287709Z",
     "start_time": "2024-01-30T10:59:17.363281041Z"
    }
   },
   "outputs": [],
   "source": [
    "Nx = 100  # number of collocation points\n",
    "hiddenDimensions = [100]  # definition of hidden layers\n",
    "activationFunction = (\n",
    "    torch.nn.Tanh()\n",
    ")  # if this is changed, also adapt the initialization\n",
    "\n",
    "epochs = 5000  # number of epochs\n",
    "lr = 5e-3  # learning rate\n",
    "selectOptimizer = \"Adam\"\n",
    "\n",
    "# epochs = 500\n",
    "# selectOptimizer = \"LBFGS\"\n",
    "# lr = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309db2e-aa72-4e72-bbd5-0d1df04fa0bf",
   "metadata": {},
   "source": [
    "**neural network & optimizer setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66f248-a5c1-4ca7-8552-41ffbe2e7828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.375849101Z",
     "start_time": "2024-01-30T10:59:17.373787364Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NN(1, hiddenDimensions, 1, activationFunction)\n",
    "model.apply(initWeights)\n",
    "if selectOptimizer == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "elif selectOptimizer == \"LBFGS\":\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2fddfc-395b-4339-bebe-6558fde75679",
   "metadata": {},
   "source": [
    "**training grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8609cae-76eb-450e-9b84-75a69068c7a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:17.409830962Z",
     "start_time": "2024-01-30T10:59:17.377521329Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(0, L, Nx, requires_grad=True).unsqueeze(1)\n",
    "\n",
    "# boundary points\n",
    "xB = torch.tensor([uBi[2] for uBi in uB]).unsqueeze(1).to(torch.float32)\n",
    "xB.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f755e-e923-49d3-954c-bf09cd8ee74d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bca03-41d4-4a84-9945-326f7f59c3a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:25.116773788Z",
     "start_time": "2024-01-30T10:59:17.410187921Z"
    }
   },
   "outputs": [],
   "source": [
    "differentialEquationLossHistory = np.zeros(epochs)\n",
    "boundaryConditionLossHistory = np.zeros(epochs)\n",
    "costHistory = np.zeros(epochs)\n",
    "\n",
    "start = time.perf_counter()\n",
    "start0 = start\n",
    "for epoch in range(epochs):\n",
    "    # predict displacements\n",
    "    uPred = getDisplacements(model, x)\n",
    "    uBPred = getDisplacements(model, xB)\n",
    "\n",
    "    lossTerms = getLossTerms(x, xB, uPred, uBPred, E(x) * A(x), distLoad(x), uB)\n",
    "    differentialEquationLossHistory[epoch] = lossTerms[0].detach()\n",
    "    boundaryConditionLossHistory[epoch] = lossTerms[1].detach()\n",
    "    costHistory[epoch] = getCostFunction(lossTerms).detach()\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        uPred = getDisplacements(model, x)\n",
    "        uBPred = getDisplacements(model, xB)\n",
    "        lossTerms = getLossTerms(x, xB, uPred, uBPred, E(x) * A(x), distLoad(x), uB)\n",
    "        cost = getCostFunction(lossTerms)\n",
    "        cost.backward(retain_graph=True)\n",
    "        return cost\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        elapsedTime = (time.perf_counter() - start) / 100\n",
    "        string = \"Epoch: {}/{}\\t\\tDifferential equation loss = {:2e}\\t\\tBoundary condition closs = {:2e}\\nCost = {:2e}\\t\\tElapsed time = {:2f}\"\n",
    "        # Format string and print\n",
    "        print(\n",
    "            string.format(\n",
    "                epoch,\n",
    "                epochs - 1,\n",
    "                differentialEquationLossHistory[epoch],\n",
    "                boundaryConditionLossHistory[epoch],\n",
    "                costHistory[epoch],\n",
    "                elapsedTime,\n",
    "            )\n",
    "        )\n",
    "        start = time.perf_counter()\n",
    "elapsedTime = time.perf_counter() - start0\n",
    "string = \"Total elapsed time: {:2f}\\nAverage elapsed time per epoch: {:2f}\"\n",
    "print(string.format(elapsedTime, elapsedTime / epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e63a9d-ea31-4930-90bb-b429637ca35c",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b677c7-9d31-4451-8562-8aa347e04726",
   "metadata": {},
   "source": [
    "**training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6c235-0210-40aa-a4d4-b93afc51989f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:25.365115912Z",
     "start_time": "2024-01-30T10:59:25.127179441Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Cost function $C$\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.plot(costHistory, \"k\", linewidth=2, label=\"Cost $C$\")\n",
    "ax.plot(\n",
    "    differentialEquationLossHistory,\n",
    "    \"r:\",\n",
    "    linewidth=2,\n",
    "    label=\"Differential equation loss $\\\\mathcal{L}_{\\\\mathcal{N}}$\",\n",
    ")\n",
    "ax.plot(\n",
    "    boundaryConditionLossHistory,\n",
    "    \"b--\",\n",
    "    linewidth=2,\n",
    "    label=\"Boundary condition loss $\\\\mathcal{L}_{\\\\mathcal{B}}$\",\n",
    ")\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f6de0-2ef2-4c1d-bad3-714c954ac14f",
   "metadata": {},
   "source": [
    "**displacement prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd55fa0-2d9e-4e79-be43-3f4164db12ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T10:59:25.534065636Z",
     "start_time": "2024-01-30T10:59:25.368117077Z"
    }
   },
   "outputs": [],
   "source": [
    "xTest = torch.linspace(0, L, 1000).unsqueeze(1)\n",
    "uPredTest = getDisplacements(model, xTest).detach()\n",
    "uPred = getDisplacements(model, x).detach()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"displacement $u$\")\n",
    "\n",
    "ax.plot(xTest, uAnalytic(xTest), \"gray\", linewidth=2, label=\"analytical solution\")\n",
    "ax.plot(xTest, uPredTest, \"k:\", linewidth=2, label=\"prediction\")\n",
    "ax.plot(x.detach(), uPred, \"rs\", markersize=6, label=\"collocation points\")\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
